def k_means_algorithm(n_clusters: int, all_pixels: np.ndarray):

    random_indices = np.random.choice(all_pixels.shape[0], n_clusters, replace=False)
    centroids = all_pixels[random_indices]

    labels = []
    diff = 0.1

    while diff >= 0.0001:
        labels = []

        for pixel in all_pixels:
            distances = np.sqrt(np.sum((centroids - pixel) **2, axis = 1))
            cluster_num = np.argmin(distances)
            labels.append(cluster_num)

        labels = np.array(labels)

        cluster_indices = []
        for i in range(n_clusters):
            cluster_indices.append(np.argwhere(labels == i))

        cluster_centers = []
        empty_clusters = 0
        for i, indices in enumerate(cluster_indices):
            if len(indices) == 0:
                empty_clusters += 1
                cluster_centers.append(centroids[i])
            else:
                cluster_centers.append(np.mean(all_pixels[indices], axis=0)[0])

        if empty_clusters > 0:
            print(f"Warning: {empty_clusters} empty clusters detected.")

        diff = np.max(centroids - np.array(cluster_centers))

        if (diff< 0.0001):
            n_clusters = centroids 
        else:
            centroids = np.array(cluster_centers)
    return n_clusters, labels

dominant_colors = 4
centers, labels = k_means_algorithm(dominant_colors, all_pixels)
centers = np.array(centers, dtype='uint8')

def analysis_colors_and_plot(centers: np.ndarray):

    colors = []
    plt.figure(0,figsize=(8,2))

    colors = []
    i = 1

    for each_col in centers:
        plt.subplot(1,centers.shape[0],i)
        plt.axis("off")
        i+=1
        
        colors.append(each_col)
        
        a = np.zeros((100,100,3),dtype='uint8')
        a[:,:,:] = each_col
        plt.imshow(a)
        
    plt.show()
    return colors

colors = analysis_colors_and_plot(centers)

def match_color_to_all_pixels(colors: list, labels: np.ndarray, new_img: np.ndarray, original_shape: tuple) -> np.ndarray:
   
    for ix in range(new_img.shape[0]):
        new_img[ix] = colors[labels[ix]]
        
    new_img = new_img.reshape((original_shape))
      
    return new_img

width, height, chanles = im.shape
new_img = np.zeros((width*height,chanles),dtype='uint8')
print(new_img.shape)

new_img = match_color_to_all_pixels(colors, labels, new_img, original_shape)

plt.imshow(new_img)
plt.show() 

im = cv2.imread('./elephant.jpg') # Reads an image into BGR Format
im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)
original_shape = im.shape

plt.imshow(im) # as RGB Format
plt.show()

all_pixels = im.reshape((-1, 3))

dominant_colors = [2, 4, 6, 8, 10]
for n_clusters in dominant_colors:
    centers, labels = k_means_algorithm(n_clusters, all_pixels)

    centers = np.array(centers, dtype='uint8')

    colors = analysis_colors_and_plot(centers)

    new_img = np.zeros(all_pixels.shape, dtype='uint8')

    new_img = match_color_to_all_pixels(colors, labels, new_img, original_shape)

    plt.imshow(new_img)
    plt.title(f"Segmented Image (K={n_clusters})")
    plt.show()

#Example for features and segmentation via FCN

from torchvision.io.image import read_image
from torchvision.models.segmentation import fcn_resnet50, FCN_ResNet50_Weights
from torchvision.transforms.functional import to_pil_image
import matplotlib.pyplot as plt

img = read_image("./dog.jpg")

weights = FCN_ResNet50_Weights.DEFAULT
model = fcn_resnet50(weights=weights)
model.eval()

preprocess = weights.transforms()

batch = preprocess(img).unsqueeze(0)

prediction = model(batch)["out"]

normalized_masks = prediction.softmax(dim=1)
class_to_idx = {cls: idx for (idx, cls) in enumerate(weights.meta["categories"])}
mask = normalized_masks[0, class_to_idx["dog"]]
mask_img = to_pil_image(mask)

plt.imshow(mask_img)

#Segment image via features from FCN and K-means, set K = 2, 4, 6, 8

from torch.nn import functional as F
import numpy as np

orginal_features = model.backbone(batch)["out"]
features = F.interpolate(orginal_features, size=img.shape[-2:], mode="bilinear", align_corners=False)
features = (features.squeeze(0).reshape((2048, -1))).permute(1, 0).detach().numpy() # Now, features is of shape (H*W, C), where C is learned features instead of colors

# Perform k-means clustering on the features

dominant_colors = [2, 4, 6, 8]
colors = [(255, 0, 0),    
          (0, 255, 0),   
          (0, 0, 255),   
          (255, 255, 0),  
          (255, 0, 255),  
          (0, 255, 255),  
          (128, 0, 128), 
          (255, 165, 0)] 

for i in dominant_colors:
    centers, labels = k_means_algorithm(i, features)
    channels, width, height = img.shape

    centers = np.array(centers, dtype='uint8')
        
    new_img = np.zeros((width * height, channels), dtype='uint8')
    new_img = match_color_to_all_pixels(colors, labels, new_img, (width, height, channels))
    new_img = new_img.reshape((width, height, channels))
    
    plt.imshow(new_img)
    plt.title(f'k={i}')
    plt.show()

chanles, height, width  = img.shape
ogrinal_shape = (height, width, chanles)

new_img = np.zeros((width*height,chanles), dtype='uint8')

colors = [(255, 0, 0),    
          (0, 255, 0),   
          (0, 0, 255),   
          (255, 255, 0),  
          (255, 0, 255),  
          (0, 255, 255),  
          (128, 0, 128), 
          (255, 165, 0)] 

new_img = match_color_to_all_pixels(colors, labels, new_img, original_shape)
new_img = new_img.reshape((height, width, chanles))

plt.imshow(new_img)
plt.show()
